{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CS-340 Assignment 3**\n",
    "### **Eric Wallace**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:53: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,676,842\n",
      "Trainable params: 1,676,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 101s 3ms/step - loss: 1.7994 - accuracy: 0.3471 - val_loss: 1.6033 - val_accuracy: 0.4151\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 96s 2ms/step - loss: 1.3598 - accuracy: 0.5164 - val_loss: 1.1794 - val_accuracy: 0.5788\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 95s 2ms/step - loss: 1.1420 - accuracy: 0.5968 - val_loss: 1.0648 - val_accuracy: 0.6252\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 91s 2ms/step - loss: 0.9970 - accuracy: 0.6530 - val_loss: 0.9190 - val_accuracy: 0.6816\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 94s 2ms/step - loss: 0.9009 - accuracy: 0.6844 - val_loss: 0.8313 - val_accuracy: 0.7068\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 93s 2ms/step - loss: 0.8270 - accuracy: 0.7113 - val_loss: 0.8102 - val_accuracy: 0.7203\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 92s 2ms/step - loss: 0.7673 - accuracy: 0.7325 - val_loss: 0.7711 - val_accuracy: 0.7327\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 106s 3ms/step - loss: 0.7163 - accuracy: 0.7495 - val_loss: 0.8856 - val_accuracy: 0.7025\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 91s 2ms/step - loss: 0.6796 - accuracy: 0.7643 - val_loss: 0.7269 - val_accuracy: 0.7535\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 91s 2ms/step - loss: 0.6477 - accuracy: 0.7774 - val_loss: 0.7194 - val_accuracy: 0.7683\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 92s 2ms/step - loss: 0.6192 - accuracy: 0.7865 - val_loss: 0.7702 - val_accuracy: 0.7430\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 92s 2ms/step - loss: 0.5957 - accuracy: 0.7964 - val_loss: 1.0459 - val_accuracy: 0.6977\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 92s 2ms/step - loss: 0.5811 - accuracy: 0.8026 - val_loss: 1.0438 - val_accuracy: 0.7016\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 103s 3ms/step - loss: 0.5746 - accuracy: 0.8058 - val_loss: 1.0286 - val_accuracy: 0.7049\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 92s 2ms/step - loss: 0.5685 - accuracy: 0.8056 - val_loss: 0.7972 - val_accuracy: 0.7585\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 110s 3ms/step - loss: 0.5548 - accuracy: 0.8124 - val_loss: 0.7804 - val_accuracy: 0.7707\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 105s 3ms/step - loss: 0.5489 - accuracy: 0.8127 - val_loss: 0.7637 - val_accuracy: 0.7821\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 99s 2ms/step - loss: 0.5486 - accuracy: 0.8173 - val_loss: 0.8007 - val_accuracy: 0.7726\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 92s 2ms/step - loss: 0.5460 - accuracy: 0.8164 - val_loss: 0.7535 - val_accuracy: 0.7800\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 109s 3ms/step - loss: 0.5416 - accuracy: 0.8188 - val_loss: 0.8378 - val_accuracy: 0.7840\n",
      "Testing...\n",
      "10000/10000 [==============================] - 11s 1ms/step\n",
      "\n",
      "Test score: 0.8544288459777832\n",
      "Test accuracy: 0.7839999794960022\n",
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a1c2c4bb7e6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;31m# summarize history for accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop, Adadelta\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "NUM_TO_AUGMENT = 5\n",
    "\n",
    "#constant\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()\n",
    "\n",
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data() \n",
    "\n",
    "# convert to categorical\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES) \n",
    "\n",
    "# float and normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM,\n",
    "\tmetrics=['accuracy'])\n",
    "\n",
    "# network\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest')  # randomly flip images\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "for x_aug in datagen.flow(X_train, Y_train, batch_size=9):\n",
    "    for i in range(0, 9):\n",
    "        plt.subplot(330 + 1 + i)\n",
    "        plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.show()\n",
    "    break\n",
    "          \n",
    "\n",
    "history = history = model.fit(X_train, Y_train, batch_size=BATCH_SIZE,\n",
    "\tepochs=NB_EPOCH, validation_split=VALIDATION_SPLIT, \n",
    "\tverbose=VERBOSE)\n",
    "print('Testing...')\n",
    "score = model.evaluate(X_test, Y_test, batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ethical and privacy concerns exposed by this algorithm are very possible.\n",
    "\n",
    "In reference to the question of could this algorithm be used for photos of people's faces and the answer is yes.  As outlined in my discussion post for this week, the situation produced by this algorithm may be very similar to the bias created by the Google Photos application in 2015 One of the most notable ethical and privacy implications in AI is data input and algorithms, they are two of the most common entry points for bias in AI.  Data used to train from real-world scenarios and created by humans will inexplicably contain bias (Niral Sutaria, 2022).  Regarding the algorithm I created, possible biases that could produce ethical or privacy concerns could be the photos used to train the AI did not include enough diversity which could result in the incorrect categorization of photos.  For instance, if test data was not diverse enough, the AI could incorrectly identify men with long hair as women and women with short hair as men.\n",
    "\n",
    "Another issue that could present ethical concerns is the fact so much focus is given to the performance of the algorithms or data scientists or engineers do not have the ability to identify bias which could raise ethical concerns (Niral Sutaria, 2022).  One thing that I noticed myself while reading the content in the book for this course is how much focus is given to the performance and accuracy of the algorithms.  I understand performance and accuracy is a good metric to go from but how accurate is the algorithms if the test data contains bias or is not diverse enough to correctly categorize photos in totality.  If the test data is not broad enough to cover the entire spectrum of photos it must categorize it could introduce ethical concerns.\n",
    "\n",
    "Addressing privacy concerns is a little bit different.  In my opinion the introduction of privacy concerns come as a result of oversight.  Not stripping away personal information and metadata related to photos must be done or at the very least randomize the data contained within the metadata.  The privacy concerns raised by AI is very large, there is an ongoing debate right now as to move forward with legislation to address privacy concerns (Kerry, 2020).  The article also raises one of the major concerns with privacy concerns in relation to photos and that is facial recognitions.  What is an Ai violates your privacy by illegally accessing photos in efforts to identify a person by facial recognition and what other concerns does it raise due to incorrectly identifying someone (Kerry, 2020).\n",
    "\n",
    "The last thing I would like to cover with privacy concerns with photos.  What is the test data used to train an AI in which no personal information was divulged but the random data was indeed biased.  This could lead AI would infer sensitive information related to medical conditions or political views based on a person’s figure or location (Machine Learning, 2022).  For instance, what if an AI made the inferences that a person based on a photo had a heart condition or because they are from the south, they are likely to be Republican.\n",
    "\n",
    "The ethical and privacy concerns raised by AI are real and is something that must be addressed.  Whether it be through a set of standards or regulations has yet to be seen.  A company creating an AI that deploys software and they miss something so simple like what happened with the Google Photos app in 2015, there should be repercussions.  No one can convince me that the issue was not found prior to the launch during the testing of the AI, not something that simple and easy to introduce.  On the future will tell where things go and how the issues will be addressed.\n",
    "\n",
    "\n",
    "References\n",
    "\n",
    "Kerry, C. (2020). Protecting privacy in an AI-driven world. Brookings.edu. https://www.brookings.edu/research/protecting-privacy-in-an-ai-driven-world/\n",
    "\n",
    "Machine Learning. (2022). What are the key privacy concerns associated with machine learning? LinkedIN. https://www.linkedin.com/pulse/what-key-privacy-concerns-associated-machine-/\n",
    "\n",
    "Niral Sutaria, C., ACA. (2022). Bias and ethical concerns in machine learning. https://www.isaca.org/resources/isaca-journal/issues/2022/volume-4/bias-and-ethical-concerns-in-machine-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
